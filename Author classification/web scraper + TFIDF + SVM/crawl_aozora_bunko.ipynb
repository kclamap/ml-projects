{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I am trying to download a corpus called Aozora Bunko (青空文庫) for later use in training a author classification machinea learning model. I have searched by google a website where each book in the corpus can be browsed online, i.e. https://archive.org/details/aozorabunko. However, it does not provide a one-click download for the whole corpus so..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, try to download one book, this will be the very core functionality of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      " <!-- __ _ _ _ __| |_ (_)__ _____\n",
      "    / _` | '_/ _| ' \\| |\\ V / -_)\n",
      "    \\__,_|_| \\__|_||_|_| \\_/\\___| -->\n",
      " <head data-release=\"896fb722\">\n",
      "  <title>\n",
      "   Full text of \"人間失格\"\n",
      "  </title>\n",
      "  <meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n",
      "  <meta content=\"Q2YSouphkkgHkFNP7FgAkc4TmBs1Gmag3uGNndb53B8\" name=\"google-site-verification\"/>\n",
      "  <meta content=\"bpjKvUvsX0lxfmjg19TLblckWkDpnptZEYsBntApxUk\" name=\"google-site-verification\"/>\n",
      "  <script>\n",
      "   /* @licstart  The following is the entire license notice for the\n",
      " * JavaScript code in this page.\n",
      " *\n",
      " * This program is free software: you can redistribute it and/or modify\n",
      " * it under the terms of the GNU Affero General Public License as published by\n",
      " * the Free Software Foundation, either version 3 of the License, or\n",
      " * (at your option) any later version.\n",
      " *\n",
      " * This program is distributed in the hope that it will be useful,\n",
      " * but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
      " * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
      " * GNU Affero General Public License for more details.\n",
      " *\n",
      " * You should have received a copy of the GNU Affero General Public License\n",
      " * along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
      " *\n",
      " * @licend  The above is the entire license notice\n",
      " * for the JavaScript code in this page.\n",
      " */\n",
      "  </script>\n",
      "  <script>\n",
      "   window.archive_setup=[]\n",
      "  </script>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <script src=\"//archive.org/ext/build/npm/jquery/dist/jquery.min.js?v1.12.4\" type=\"text/javascript\">\n",
      "  </script>\n",
      "  <script src=\"//archive.org/ext/build/npm/jquery-ui.min.js?v1.12.1\" type=\"text/javascript\">\n",
      "  </script>\n",
      "  <script src=\"//archive.org/ext/build/npm/bootstrap/dist/js/bootstrap.min.js?v3.0.0\" type=\"text/javascript\">\n",
      "  </script>\n",
      "  <script src=\"//archive.org/ext/components/npm/clipboard/dist/clipboard.js?v=896fb722\" type=\"text/javascript\">\n",
      "  </script>\n",
      "  <script src=\"//archive.org/ext/components/npm/@babel/polyfill/dist/polyfill.min.js?\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(\"https://archive.org/stream/aozorabunko_00301/aozorabunko_00301_djvu.txt\")\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "print(soup.prettify()[:2000]) # You may want to download this notebook and run by yourself to see the full result where necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually looks quite good because the book contents we want are already sitting there, but we just need some more subtractions, so let's do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_content = str(soup.find_all(\"pre\")[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "はしがき \n",
      "\n",
      "\n",
      "\n",
      "私 は、 その 男の 写真 を 三 葉、 見た ことがある。 \n",
      "\n",
      "一葉 は、 その 男の、 幼年時代、 とで も 言うべき であ \n",
      "\n",
      "ろうか、 十 歳 前後 かと 推定され る 頃の 写真であって、 \n",
      "\n",
      "その子 供が 大勢の 女の ひとに 取り かこまれ、 (それ は、 \n",
      "\n",
      "その子 供の 姉た ち、 妹た ち、 それから、 従姉妹た ちか \n",
      "\n",
      "はかま \n",
      "\n",
      "と 想像され る) 庭園の 池の ほとりに、 荒い 縞の 袴 を は \n",
      "\n",
      "いて 立ち、 首 を 三十 度 ほど 左に 傾け、 醜く 笑って いる \n",
      "\n",
      "\n",
      "\n",
      "写真で ある。 醜く？ けれども、 鈍い 人た ち (つまり、 \n",
      "\n",
      "美醜な どに 関心 を 持たぬ 人た ち) は、 面白く も 何とも \n",
      "\n",
      "無い ような 顔 をして、 \n",
      "\n",
      "「可愛い 坊ちゃんで すね」 \n",
      "\n",
      "といい 加減な お世辞 を 言 つても、 まんざら 空お 世辞 \n",
      "\n",
      "に 聞えない くらいの、 S ぼ わば 通俗の 「可愛らし さ」 み \n",
      "\n",
      "たいな 影 も その子 供の 笑顔に 無い わけで はない の だが、 \n",
      "\n",
      "しかし、 いささか でも、 美醜に 就いての 訓練 を 経て 来 \n",
      "\n",
      "た ひとなら、 ひとめ 見て すぐ、 \n",
      "\n",
      "「なんて、 いやな 子供 だ」 \n",
      "\n",
      "と 頗る 不快そう に 眩き、 毛虫で も 払いの ける 時の \n",
      "\n",
      "\n",
      "\n",
      "こんな 不思議な 美貌の 青年 を 見た 事が、 いちど も 無 \n",
      "\n",
      "かった。 \n",
      "\n",
      "もう 一葉の 写真 は、 最も 奇怪な ものである。 まるで \n",
      "\n",
      "もう、 としの 頃が わからない。 頭 はいく ぶん 白髪の よ \n",
      "\n",
      "うで ある。 それが、 ひどく 汚い 部屋 (部屋の 壁が 三箇 \n",
      "\n",
      "所 ほど 崩れ落ち ている のが、 その 写真に ハツ キリ 写つ \n",
      "\n",
      "ている) の 片隅で、 小さい 火鉢に 両手 を かざし、 こん \n",
      "\n",
      "ど は 笑って いない。 どんな 表情 も 無い。 謂わば、 坐つ \n",
      "\n",
      "て 火鉢に 両手 を かざしながら、 自然に 死んで いるよう \n",
      "\n",
      "な、 まことにい まわしい、 不吉な においの する 写真で \n",
      "\n",
      "あった。 奇怪な の は、 それだけ でない。 その 写真に は、 \n",
      "\n",
      "\n",
      "\n",
      "第 一 の 手 1 一目 \n",
      "\n",
      "\n",
      "\n",
      "恥の 多い 生涯 を 送って 来ました。 \n",
      "\n",
      "自分に は、 人間の 生活と いう ものが、 見当つ かない \n",
      "\n",
      "のです。 自分 は 東北の 田舎に 生れました ので、 汽車 を \n",
      "\n",
      "はじめて 見た の は、 よほど 大きくな つてから でした。 \n",
      "\n",
      "自分 は 停車場の ブリッジ を、 上って、 降りて、 そうし \n",
      "\n",
      "て それが 線路 を またぎ 越える ために 造られた もの だと \n",
      "\n",
      "\n",
      "\n",
      "式の ような もので、 家族が 日に 三度々々、 時刻 をき め \n",
      "\n",
      "て 薄暗い 一 部屋に 集り、 お膳 を 順序 正しく 並べ、 食べ \n",
      "\n",
      "たくなくても 無言で ごはん を嚙 みながら、 うつむき、 \n",
      "\n",
      "家中に うごめい ている 霊た ちに 祈る ための もの かも 知 \n",
      "\n",
      "れ ない、 とさえ 考えた 事が あるく らいでした。 \n",
      "\n",
      "めし を 食べなければ 死ぬ、 という 言葉 は、 自分の 耳 \n",
      "\n",
      "に は、 ただ ィャ なお どかしと しか 聞え ませんで した。 \n",
      "\n",
      "その 迷信 は、 (いまでも 自分に は、 何だか 迷信の ように \n",
      "\n",
      "思われて ならない のです が) しかし、 いつも 自分に 不 \n",
      "\n",
      "安と 恐怖 を 与えました。 人間 は、 めし を 食べなければ \n",
      "\n",
      "死ぬ から、 そのために 働いて、 めし を 食べなければ な \n",
      "\n",
      "\n",
      "\n",
      "店先で 笑い ましたよ。 葉 蔵 を 早く ここへ 呼びなさい」 \n",
      "\n",
      "また 一 方、 自分 は、 下男 や 下女た ち を 洋室に 集めて、 \n",
      "\n",
      "下男の ひとりに 滅茶苦茶に ピ ァノの キイ をた たかせ、 \n",
      "\n",
      "(田舎で はあり ましたが、 その 家に は、 たいて いのもの \n",
      "\n",
      "が、 そろって いました) 自分 は その 出鳕 目の 曲に 合せ \n",
      "\n",
      "て、 イン デ ヤンの 踊り を 踊って 見せて、 皆 を 大笑い さ \n",
      "\n",
      "せました。 次兄 は、 フラッシュ を 焚いて、 自分の イン \n",
      "\n",
      "デ ヤン 踊り を 撮影し て、 その 写真が 出来た の を 見る と、 \n",
      "\n",
      "さ ら さ \n",
      "\n",
      "自分の 腰布 (それ は 更紗の 風呂敷でした) の 合せ 目 か \n",
      "\n",
      "ら、 小さい お チンボが 見えて いたので、 これが また 家 \n",
      "\n",
      "中の 大笑いでした。 自分に とって、 これ また 意外の 成 \n",
      "\n",
      "\n",
      "\n",
      "ばかり 書き、 先生から 注意 されても、 しかし、 自分 は、 \n",
      "\n",
      "やめませんでした。 先生 は、 実は こ\n"
     ]
    }
   ],
   "source": [
    "print(book_content[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from the book contents, we also need to collect the author name and other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      " <!-- __ _ _ _ __| |_ (_)__ _____\n",
      "    / _` | '_/ _| ' \\| |\\ V / -_)\n",
      "    \\__,_|_| \\__|_||_|_| \\_/\\___| -->\n",
      " <head data-release=\"896fb722\">\n",
      "  <title>\n",
      "   人間失格 : Dazai,Osamu 太宰,治 (1909-1948) : Free Download, Borrow, and Streaming : Internet Archive\n",
      "  </title>\n",
      "  <meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n",
      "  <meta content=\"Q2YSouphkkgHkFNP7FgAkc4TmBs1Gmag3uGNndb53B8\" name=\"google-site-verification\"/>\n",
      "  <meta content=\"bpjKvUvsX0lxfmjg19TLblckWkDpnptZEYsBntApxUk\" name=\"google-site-verification\"/>\n",
      "  <script>\n",
      "   /* @licstart  The following is the entire license notice for the\n",
      " * JavaScript code in this page.\n",
      " *\n",
      " * This program is free software: you can redistribute it and/or modify\n",
      " * it under the terms of the GNU Affero General Public License as published by\n",
      " * the Free Software Foundation, either version 3 of the License, or\n",
      " * (at your option) any later version.\n",
      " *\n",
      " * This program is distributed in the hope that it will be useful,\n",
      " * but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
      " * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
      " * GNU Affero General Public License for more details.\n",
      " *\n",
      " * You should have received a copy of the GNU Affero General Public License\n",
      " * along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
      " *\n",
      " * @licend  The above is the entire license notice\n",
      " * for the JavaScript code in this page.\n",
      " */\n",
      "  </script>\n",
      "  <script>\n",
      "   window.archive_setup=[]\n",
      "  </script>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <script src=\"//archive.org/ext/build/npm/jquery/dist/jquery.min.js?v1.12.4\" type=\"text/javascript\">\n",
      "  </script>\n",
      "  <script src=\"//archive.org/ext/build/npm/jquery-ui.min.js?v1.12.1\" type=\"text/javascript\">\n",
      "  </script>\n",
      "  <script src=\"//archive.org/ext/build/npm/bootstrap/dist/js/bootstrap.min.js?v3.0.0\" type=\"text/javascript\">\n",
      "  </script>\n",
      "  <script src=\"//archive.org/ext/components/npm/clipboard/dist/clipboard.js?v=896fb722\" type=\"text/javascript\">\n",
      "  </script>\n",
      "  <script s\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(\"https://archive.org/details/aozorabunko_00301\")\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "print(soup.prettify()[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人間失格\n"
     ]
    }
   ],
   "source": [
    "book_title = soup.find_all(\"span\", attrs={\"itemprop\" : \"name\"})[0].text\n",
    "print(book_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "おさむだざい\n"
     ]
    }
   ],
   "source": [
    "metadata_name = soup.find_all(\"dt\")\n",
    "metadata_value = soup.find_all(\"dd\")\n",
    "for idx, metadatum_name in enumerate(metadata_name):\n",
    "    if \"Author-first-name-pron\" in metadatum_name:\n",
    "        author_first_name = metadata_value[idx].text\n",
    "    if \"Author-last-name-pron\" in metadatum_name:\n",
    "        author_last_name = metadata_value[idx].text\n",
    "author_name = author_first_name + author_last_name\n",
    "print(author_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything worked well so far. Now we are ready to crawl the whole corpus!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_book_content(book_id):\n",
    "    response = requests.get(\"https://archive.org/stream/aozorabunko_\"+book_id+\"/aozorabunko_\"+book_id+\"_djvu.txt\")\n",
    "    if response.status_code == 404:\n",
    "        return None\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    pre_elements = soup.find_all(\"pre\")\n",
    "    book_content = str(pre_elements[0].text)\n",
    "    \n",
    "    return book_content\n",
    "\n",
    "def crawl_book_title_and_author(book_id):\n",
    "    response = requests.get(\"https://archive.org/details/aozorabunko_\"+book_id)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    book_title = soup.find_all(\"span\", attrs={\"itemprop\" : \"name\"})[0].text\n",
    "    \n",
    "    metadata_name = soup.find_all(\"dt\")\n",
    "    metadata_value = soup.find_all(\"dd\")\n",
    "    author_first_name = None\n",
    "    author_last_name = None\n",
    "    for idx, metadatum_name in enumerate(metadata_name):\n",
    "        if \"Author-first-name-pron\" in metadatum_name or \"Authorfirstnamepron\" in metadatum_name:\n",
    "            author_first_name = metadata_value[idx].text\n",
    "        if \"Author-last-name-pron\" in metadatum_name or \"Authorlastnamepron\" in metadatum_name:\n",
    "            author_last_name = metadata_value[idx].text\n",
    "    \n",
    "    if author_first_name != None and author_last_name != None:\n",
    "        author_name = author_first_name + author_last_name\n",
    "    elif author_first_name != None and author_last_name == None:\n",
    "        author_name = author_first_name\n",
    "    elif author_first_name == None and author_last_name != None:\n",
    "        author_name = author_last_name\n",
    "    else:\n",
    "        author_name = None\n",
    "    \n",
    "    return book_title, author_name\n",
    "    \n",
    "def crawl_book_data(book_id):\n",
    "    # id has to be 5-digit, zero-filled\n",
    "    book_id = str(book_id).zfill(5)\n",
    "    book_content = crawl_book_content(book_id)\n",
    "    if book_content:\n",
    "        book_title, author = crawl_book_title_and_author(book_id)\n",
    "        time.sleep(3)\n",
    "        return {\"book_content\": book_content, \"book_title\": book_title, \"author\": author}\n",
    "    else:\n",
    "        return {\"book_content\": None, \"book_title\": None, \"author\": None}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how long it takes to download a book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = crawl_book_data(301)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have 4000 books to download, it would take almost 7 hours to finish. Although is still affordable, but let's try to speed it up anyways by multithreading. (Hoping that there isn't a strict rate limit of get requests)\n",
    "\n",
    "A little trick is to intentional sleep for a few seconds in between the get requests, otherwise a usual scenairo is when a website receive a few tens request from the same IP, it simply blocks the IP.\n",
    "\n",
    "Another thing I have done is to save the data crawled from time to time such that if the for-loop is interupted for whatever reason, I can start from a \"save point\".\n",
    "\n",
    "Besides, I include an early return condition if status_code of the response is 404, this further speeds up the process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of corpus now: 0\n",
      "Starting id is 0\n"
     ]
    }
   ],
   "source": [
    "corpus_dir = 'data/corpus.json'\n",
    "\n",
    "if os.path.isfile(corpus_dir):\n",
    "    with open(corpus_dir, 'r') as file:\n",
    "        corpus = json.load(file)\n",
    "        start_id = int(max(corpus.keys()))\n",
    "else:\n",
    "    corpus = {}\n",
    "    start_id = 0\n",
    "    \n",
    "print(\"Size of corpus now: \" + str(len(corpus)))\n",
    "print(\"Starting id is \" + str(start_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ffac0699c643ed8d4ca0da8a5f8434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(crawl_book_data, param) for param in range(start_id, 50000, 1)]\n",
    "    #return_value = {str(idx).zfill(5): f.result() for idx, f in tqdm(enumerate(futures))}\n",
    "    for idx, f in tqdm(enumerate(futures)):\n",
    "        corpus[str(idx).zfill(5)] = f.result()\n",
    "        \n",
    "        if idx % 1000 == 0 and idx >= 1000:\n",
    "            with open(corpus_dir,'w') as file:\n",
    "                json.dump(corpus, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all the offsetting effect between multithreading and time.sleep, it finally took us around 75 minutes. Let's check whether all the 4000 books lies in a id range below 50000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "meaningful_content = []\n",
    "for key in corpus.keys():\n",
    "    if corpus[key]['book_content'] != None:\n",
    "        meaningful_content.append(idx)\n",
    "print(len(meaningful_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NICE! As the purpose of this notebook has been achieved, this would be the end.\n",
    "\n",
    "Thnka you for reading! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
